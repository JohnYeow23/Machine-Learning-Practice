{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# doc2vec: How To Prep Document Vectors For Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Our Own Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doc2Vec<dm/m,d50,n5,w2,mc2,s0.001,t3>\n"
     ]
    }
   ],
   "source": [
    "# Read in data, clean it, split it into train/test, and then train a doc2vec model\n",
    "import gensim\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "pd.set_option('display.max_colwidth', 100)\n",
    "\n",
    "messages = pd.read_csv('../../../data/spam.csv', encoding='latin-1')\n",
    "# print(messages)\n",
    "messages = messages.drop(labels = [\"Unnamed: 2\", \"Unnamed: 3\", \"Unnamed: 4\"], axis = 1)\n",
    "# print(messages)\n",
    "messages.columns = [\"label\", \"text\"]\n",
    "messages['text_clean'] = messages['text'].apply(lambda x: gensim.utils.simple_preprocess(x))\n",
    "# print(messages)\n",
    "X_train, X_test, y_train, y_test = train_test_split(messages['text_clean'],\n",
    "                                                    messages['label'], test_size=0.2)\n",
    "\n",
    "tagged_docs_tr = [gensim.models.doc2vec.TaggedDocument(v, [i]) for i, v in enumerate(X_train)]\n",
    "\n",
    "d2v_model = gensim.models.Doc2Vec(tagged_docs_tr,\n",
    "                                  vector_size=50,\n",
    "                                  window=2,\n",
    "                                  min_count=2)\n",
    "print(d2v_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.58599764e-03,  8.91528092e-03,  7.63595663e-03,  6.36730948e-03,\n",
       "       -1.61670856e-02, -3.22236717e-02,  5.51937323e-04,  3.06588039e-02,\n",
       "       -4.02223319e-02, -2.18719207e-02, -6.08397182e-04, -3.77334394e-02,\n",
       "        6.14896603e-03,  1.01919016e-02, -1.77755095e-02,  1.61400940e-02,\n",
       "        2.28028763e-02,  1.18536428e-02, -1.75037310e-02, -2.88310610e-02,\n",
       "        1.25682801e-02,  3.57844420e-02,  3.98174860e-02,  2.57810741e-03,\n",
       "        2.02434007e-02, -4.56704496e-04, -2.92982105e-02, -2.45399249e-04,\n",
       "       -2.83887237e-02, -9.43346095e-06, -3.55673343e-04,  2.38960255e-02,\n",
       "       -6.84962468e-03,  2.18702271e-03, -2.51618214e-02,  3.27886567e-02,\n",
       "        1.98430717e-02,  8.39122292e-03,  1.14069125e-02, -1.57406442e-02,\n",
       "        3.95161361e-02,  8.90934560e-03,  2.87241931e-03,  6.57761050e-03,\n",
       "        4.08147871e-02,  1.07503999e-02,  1.50299473e-02, -2.09454205e-02,\n",
       "        4.84986650e-03,  2.84217056e-02], dtype=float32)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What does a document vector look like again?\n",
    "d2v_model.infer_vector(['convert', 'words', 'to', 'vectors'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How do we prepare these vectors to be used in a machine learning model?\n",
    "vectors = [[d2v_model.infer_vector(words)] for words in X_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
