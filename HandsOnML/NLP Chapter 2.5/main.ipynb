{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np  \n",
    "import matplotlib.pyplot as plt\n",
    "import string\n",
    "import re \n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>body_text</th>\n",
       "      <th>body_len</th>\n",
       "      <th>punct%</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>128</td>\n",
       "      <td>0.047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>49</td>\n",
       "      <td>0.041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>Even my brother is not like to speak with me. ...</td>\n",
       "      <td>62</td>\n",
       "      <td>0.032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>I HAVE A DATE ON SUNDAY WITH WILL!!</td>\n",
       "      <td>28</td>\n",
       "      <td>0.071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>As per your request 'Melle Melle (Oru Minnamin...</td>\n",
       "      <td>135</td>\n",
       "      <td>0.044</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                          body_text  body_len  punct%\n",
       "0      1  Free entry in 2 a wkly comp to win FA Cup fina...       128   0.047\n",
       "1      0  Nah I don't think he goes to usf, he lives aro...        49   0.041\n",
       "2      0  Even my brother is not like to speak with me. ...        62   0.032\n",
       "3      0                I HAVE A DATE ON SUNDAY WITH WILL!!        28   0.071\n",
       "4      0  As per your request 'Melle Melle (Oru Minnamin...       135   0.044"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('SMSSpamCollection.tsv', sep='\\t')\n",
    "df.columns = ['label', 'body_text']\n",
    "\n",
    "df['label'] = df['label'].map({'ham':0, 'spam':1})\n",
    "df['body_len'] = df['body_text'].apply(lambda x:len(x)- x.count(\" \"))\n",
    "df['punct%'] = df['body_text'].apply(lambda x:\n",
    "round(\n",
    "    sum(\n",
    "        [1 for char in x if char in string.punctuation]) / (len(x)- x.count(\" \")\n",
    "    )\n",
    ",3)\n",
    ")\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>body_text</th>\n",
       "      <th>body_len</th>\n",
       "      <th>punct%</th>\n",
       "      <th>split_text</th>\n",
       "      <th>misspelled%</th>\n",
       "      <th>count_lower</th>\n",
       "      <th>count_upper</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>128</td>\n",
       "      <td>0.047</td>\n",
       "      <td>[Free, entry, in, 2, a, wkly, comp, to, win, F...</td>\n",
       "      <td>0.393</td>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>49</td>\n",
       "      <td>0.041</td>\n",
       "      <td>[Nah, I, don't, think, he, goes, to, usf,, he,...</td>\n",
       "      <td>0.308</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>Even my brother is not like to speak with me. ...</td>\n",
       "      <td>62</td>\n",
       "      <td>0.032</td>\n",
       "      <td>[Even, my, brother, is, not, like, to, speak, ...</td>\n",
       "      <td>0.188</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>I HAVE A DATE ON SUNDAY WITH WILL!!</td>\n",
       "      <td>28</td>\n",
       "      <td>0.071</td>\n",
       "      <td>[I, HAVE, A, DATE, ON, SUNDAY, WITH, WILL!!]</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>As per your request 'Melle Melle (Oru Minnamin...</td>\n",
       "      <td>135</td>\n",
       "      <td>0.044</td>\n",
       "      <td>[As, per, your, request, 'Melle, Melle, (Oru, ...</td>\n",
       "      <td>0.462</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                          body_text  body_len  punct%  \\\n",
       "0      1  Free entry in 2 a wkly comp to win FA Cup fina...       128   0.047   \n",
       "1      0  Nah I don't think he goes to usf, he lives aro...        49   0.041   \n",
       "2      0  Even my brother is not like to speak with me. ...        62   0.032   \n",
       "3      0                I HAVE A DATE ON SUNDAY WITH WILL!!        28   0.071   \n",
       "4      0  As per your request 'Melle Melle (Oru Minnamin...       135   0.044   \n",
       "\n",
       "                                          split_text  misspelled%  \\\n",
       "0  [Free, entry, in, 2, a, wkly, comp, to, win, F...        0.393   \n",
       "1  [Nah, I, don't, think, he, goes, to, usf,, he,...        0.308   \n",
       "2  [Even, my, brother, is, not, like, to, speak, ...        0.188   \n",
       "3       [I, HAVE, A, DATE, ON, SUNDAY, WITH, WILL!!]        0.250   \n",
       "4  [As, per, your, request, 'Melle, Melle, (Oru, ...        0.462   \n",
       "\n",
       "   count_lower  count_upper  \n",
       "0           18            2  \n",
       "1           11            1  \n",
       "2           14            0  \n",
       "3            0            8  \n",
       "4           15            0  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['split_text'] = df['body_text'].apply(lambda x: x.split())\n",
    "\n",
    "df['misspelled%'] = df['split_text'].apply(lambda x: round(sum([1 for word in x if word.lower() not in words.words()])/ (len(x)- x.count(\" \")),3))\n",
    "df['count_lower'] = df['split_text'].apply(lambda x: len([word for word in x if word.islower()]))\n",
    "df['count_upper'] = df['split_text'].apply(lambda x: len([word for word in x if word.isupper()]))\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['split_text'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msplit_text\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m df\u001b[38;5;241m.\u001b[39mhead()\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/pandas/core/frame.py:5344\u001b[0m, in \u001b[0;36mDataFrame.drop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   5196\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdrop\u001b[39m(\n\u001b[1;32m   5197\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   5198\u001b[0m     labels: IndexLabel \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   5205\u001b[0m     errors: IgnoreRaise \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   5206\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   5207\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   5208\u001b[0m \u001b[38;5;124;03m    Drop specified labels from rows or columns.\u001b[39;00m\n\u001b[1;32m   5209\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   5342\u001b[0m \u001b[38;5;124;03m            weight  1.0     0.8\u001b[39;00m\n\u001b[1;32m   5343\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 5344\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   5345\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5346\u001b[0m \u001b[43m        \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5347\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5348\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5349\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5350\u001b[0m \u001b[43m        \u001b[49m\u001b[43minplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minplace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5351\u001b[0m \u001b[43m        \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5352\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/pandas/core/generic.py:4711\u001b[0m, in \u001b[0;36mNDFrame.drop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   4709\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m axis, labels \u001b[38;5;129;01min\u001b[39;00m axes\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m   4710\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 4711\u001b[0m         obj \u001b[38;5;241m=\u001b[39m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_drop_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4713\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inplace:\n\u001b[1;32m   4714\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_inplace(obj)\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/pandas/core/generic.py:4753\u001b[0m, in \u001b[0;36mNDFrame._drop_axis\u001b[0;34m(self, labels, axis, level, errors, only_slice)\u001b[0m\n\u001b[1;32m   4751\u001b[0m         new_axis \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mdrop(labels, level\u001b[38;5;241m=\u001b[39mlevel, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[1;32m   4752\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 4753\u001b[0m         new_axis \u001b[38;5;241m=\u001b[39m \u001b[43maxis\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4754\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mget_indexer(new_axis)\n\u001b[1;32m   4756\u001b[0m \u001b[38;5;66;03m# Case for non-unique axis\u001b[39;00m\n\u001b[1;32m   4757\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/pandas/core/indexes/base.py:7000\u001b[0m, in \u001b[0;36mIndex.drop\u001b[0;34m(self, labels, errors)\u001b[0m\n\u001b[1;32m   6998\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mask\u001b[38;5;241m.\u001b[39many():\n\u001b[1;32m   6999\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m errors \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m-> 7000\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlabels[mask]\u001b[38;5;241m.\u001b[39mtolist()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not found in axis\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   7001\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m indexer[\u001b[38;5;241m~\u001b[39mmask]\n\u001b[1;32m   7002\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdelete(indexer)\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['split_text'] not found in axis\""
     ]
    }
   ],
   "source": [
    "df.drop('split_text', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>body_text</th>\n",
       "      <th>body_len</th>\n",
       "      <th>punct%</th>\n",
       "      <th>misspelled%</th>\n",
       "      <th>count_lower</th>\n",
       "      <th>count_upper</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>128</td>\n",
       "      <td>0.047</td>\n",
       "      <td>0.393</td>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>49</td>\n",
       "      <td>0.041</td>\n",
       "      <td>0.308</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>Even my brother is not like to speak with me. ...</td>\n",
       "      <td>62</td>\n",
       "      <td>0.032</td>\n",
       "      <td>0.188</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>I HAVE A DATE ON SUNDAY WITH WILL!!</td>\n",
       "      <td>28</td>\n",
       "      <td>0.071</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>As per your request 'Melle Melle (Oru Minnamin...</td>\n",
       "      <td>135</td>\n",
       "      <td>0.044</td>\n",
       "      <td>0.462</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                          body_text  body_len  punct%  \\\n",
       "0      1  Free entry in 2 a wkly comp to win FA Cup fina...       128   0.047   \n",
       "1      0  Nah I don't think he goes to usf, he lives aro...        49   0.041   \n",
       "2      0  Even my brother is not like to speak with me. ...        62   0.032   \n",
       "3      0                I HAVE A DATE ON SUNDAY WITH WILL!!        28   0.071   \n",
       "4      0  As per your request 'Melle Melle (Oru Minnamin...       135   0.044   \n",
       "\n",
       "   misspelled%  count_lower  count_upper  \n",
       "0        0.393           18            2  \n",
       "1        0.308           11            1  \n",
       "2        0.188           14            0  \n",
       "3        0.250            0            8  \n",
       "4        0.462           15            0  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>body_text</th>\n",
       "      <th>body_len</th>\n",
       "      <th>punct%</th>\n",
       "      <th>misspelled%</th>\n",
       "      <th>count_lower</th>\n",
       "      <th>count_upper</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>128</td>\n",
       "      <td>0.047</td>\n",
       "      <td>0.393</td>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>49</td>\n",
       "      <td>0.041</td>\n",
       "      <td>0.308</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>Even my brother is not like to speak with me. ...</td>\n",
       "      <td>62</td>\n",
       "      <td>0.032</td>\n",
       "      <td>0.188</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>I HAVE A DATE ON SUNDAY WITH WILL!!</td>\n",
       "      <td>28</td>\n",
       "      <td>0.071</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>As per your request 'Melle Melle (Oru Minnamin...</td>\n",
       "      <td>135</td>\n",
       "      <td>0.044</td>\n",
       "      <td>0.462</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                          body_text  body_len  punct%  \\\n",
       "0      1  Free entry in 2 a wkly comp to win FA Cup fina...       128   0.047   \n",
       "1      0  Nah I don't think he goes to usf, he lives aro...        49   0.041   \n",
       "2      0  Even my brother is not like to speak with me. ...        62   0.032   \n",
       "3      0                I HAVE A DATE ON SUNDAY WITH WILL!!        28   0.071   \n",
       "4      0  As per your request 'Melle Melle (Oru Minnamin...       135   0.044   \n",
       "\n",
       "   misspelled%  count_lower  count_upper  \n",
       "0        0.393           18            2  \n",
       "1        0.308           11            1  \n",
       "2        0.188           14            0  \n",
       "3        0.250            0            8  \n",
       "4        0.462           15            0  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop_words = stopwords.words('english')\n",
    "ps = nltk.PorterStemmer()\n",
    "\n",
    "def clean_text(text):\n",
    "    text = ''.join([word.lower() for word in text if word not in string.punctuation])\n",
    "    tokens = re.split('\\W+',text)\n",
    "    text = [ps.stem(word) for word in tokens if word not in stop_words]\n",
    "    return text\n",
    "\n",
    "# df['body_text_clean'] = df['body_text'].apply(lambda x: clean_text(x))\n",
    "# df.drop('body_text_clean',axis=1, inplace=True) \n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(df[['body_text','body_len','punct%','misspelled%','count_lower','count_upper']], df['label'],test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>body_len</th>\n",
       "      <th>punct%</th>\n",
       "      <th>misspelled%</th>\n",
       "      <th>count_lower</th>\n",
       "      <th>count_upper</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>...</th>\n",
       "      <th>7146</th>\n",
       "      <th>7147</th>\n",
       "      <th>7148</th>\n",
       "      <th>7149</th>\n",
       "      <th>7150</th>\n",
       "      <th>7151</th>\n",
       "      <th>7152</th>\n",
       "      <th>7153</th>\n",
       "      <th>7154</th>\n",
       "      <th>7155</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19</td>\n",
       "      <td>0.316</td>\n",
       "      <td>0.667</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>54</td>\n",
       "      <td>0.056</td>\n",
       "      <td>0.125</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41</td>\n",
       "      <td>0.073</td>\n",
       "      <td>0.273</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>89</td>\n",
       "      <td>0.090</td>\n",
       "      <td>0.375</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>123</td>\n",
       "      <td>0.057</td>\n",
       "      <td>0.333</td>\n",
       "      <td>19</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 7161 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   body_len  punct%  misspelled%  count_lower  count_upper    0    1    2  \\\n",
       "0        19   0.316        0.667            1            0  0.0  0.0  0.0   \n",
       "1        54   0.056        0.125           14            1  0.0  0.0  0.0   \n",
       "2        41   0.073        0.273           10            0  0.0  0.0  0.0   \n",
       "3        89   0.090        0.375           15            0  0.0  0.0  0.0   \n",
       "4       123   0.057        0.333           19            2  0.0  0.0  0.0   \n",
       "\n",
       "     3    4  ...  7146  7147  7148  7149  7150  7151  7152  7153  7154  7155  \n",
       "0  0.0  0.0  ...   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "1  0.0  0.0  ...   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "2  0.0  0.0  ...   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "3  0.0  0.0  ...   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "4  0.0  0.0  ...   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "\n",
       "[5 rows x 7161 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf_vect = TfidfVectorizer(analyzer=clean_text)\n",
    "tfidf_vect_fit = tfidf_vect.fit(x_train['body_text'])\n",
    "\n",
    "tfidf_train = tfidf_vect_fit.transform(x_train['body_text'])\n",
    "tfidf_test = tfidf_vect_fit.transform(x_test['body_text'])\n",
    "\n",
    "x_train_tfidf_vect = pd.concat([x_train[['body_len','punct%','misspelled%','count_lower','count_upper']].reset_index(drop=True)\n",
    "            ,pd.DataFrame(tfidf_train.toarray())], axis=1)\n",
    "\n",
    "x_test_tfidf_vect = pd.concat([x_test[['body_len','punct%','misspelled%','count_lower','count_upper']].reset_index(drop=True)\n",
    "            ,pd.DataFrame(tfidf_test.toarray())], axis=1)\n",
    "\n",
    "x_train_tfidf_vect.columns =x_train_tfidf_vect.columns.astype(str) \n",
    "x_test_tfidf_vect.columns =x_test_tfidf_vect.columns.astype(str) \n",
    "\n",
    "x_train_tfidf_vect.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>body_len</th>\n",
       "      <th>punct%</th>\n",
       "      <th>misspelled%</th>\n",
       "      <th>count_lower</th>\n",
       "      <th>count_upper</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>...</th>\n",
       "      <th>7146</th>\n",
       "      <th>7147</th>\n",
       "      <th>7148</th>\n",
       "      <th>7149</th>\n",
       "      <th>7150</th>\n",
       "      <th>7151</th>\n",
       "      <th>7152</th>\n",
       "      <th>7153</th>\n",
       "      <th>7154</th>\n",
       "      <th>7155</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19</td>\n",
       "      <td>0.316</td>\n",
       "      <td>0.667</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>54</td>\n",
       "      <td>0.056</td>\n",
       "      <td>0.125</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41</td>\n",
       "      <td>0.073</td>\n",
       "      <td>0.273</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>89</td>\n",
       "      <td>0.090</td>\n",
       "      <td>0.375</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>123</td>\n",
       "      <td>0.057</td>\n",
       "      <td>0.333</td>\n",
       "      <td>19</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 7161 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   body_len  punct%  misspelled%  count_lower  count_upper  0  1  2  3  4  \\\n",
       "0        19   0.316        0.667            1            0  0  0  0  0  0   \n",
       "1        54   0.056        0.125           14            1  0  0  0  0  0   \n",
       "2        41   0.073        0.273           10            0  0  0  0  0  0   \n",
       "3        89   0.090        0.375           15            0  0  0  0  0  0   \n",
       "4       123   0.057        0.333           19            2  0  0  0  0  0   \n",
       "\n",
       "   ...  7146  7147  7148  7149  7150  7151  7152  7153  7154  7155  \n",
       "0  ...     0     0     0     0     0     0     0     0     0     0  \n",
       "1  ...     0     0     0     0     0     0     0     0     0     0  \n",
       "2  ...     0     0     0     0     0     0     0     0     0     0  \n",
       "3  ...     0     0     0     0     0     0     0     0     0     0  \n",
       "4  ...     0     0     0     0     0     0     0     0     0     0  \n",
       "\n",
       "[5 rows x 7161 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "count_vect = CountVectorizer(analyzer=clean_text)\n",
    "count_vect_fit = count_vect.fit(x_train['body_text'])\n",
    "\n",
    "count_vect_train = count_vect_fit.transform(x_train['body_text'])\n",
    "count_vect_test = count_vect_fit.transform(x_test['body_text'])\n",
    "\n",
    "x_train_count_vect = pd.concat([x_train[['body_len','punct%','misspelled%','count_lower','count_upper']].reset_index(drop=True)\n",
    "            ,pd.DataFrame(count_vect_train.toarray())], axis=1)\n",
    "\n",
    "x_test_count_vect = pd.concat([x_test[['body_len','punct%','misspelled%','count_lower','count_upper']].reset_index(drop=True)\n",
    "            ,pd.DataFrame(count_vect_test.toarray())], axis=1)\n",
    "\n",
    "x_train_count_vect.columns =x_train_count_vect.columns.astype(str) \n",
    "x_test_count_vect.columns =x_test_count_vect.columns.astype(str)\n",
    "\n",
    "x_train_count_vect.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.metrics import precision_recall_fscore_support as score\n",
    "import time "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5.532954</td>\n",
       "      <td>0.124660</td>\n",
       "      <td>0.291926</td>\n",
       "      <td>0.357877</td>\n",
       "      <td>90</td>\n",
       "      <td>150</td>\n",
       "      <td>{'max_depth': 90, 'n_estimators': 150}</td>\n",
       "      <td>0.971942</td>\n",
       "      <td>0.985410</td>\n",
       "      <td>0.973064</td>\n",
       "      <td>0.979775</td>\n",
       "      <td>0.974157</td>\n",
       "      <td>0.976870</td>\n",
       "      <td>0.005050</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>10.040416</td>\n",
       "      <td>0.162150</td>\n",
       "      <td>0.159551</td>\n",
       "      <td>0.036358</td>\n",
       "      <td>None</td>\n",
       "      <td>300</td>\n",
       "      <td>{'max_depth': None, 'n_estimators': 300}</td>\n",
       "      <td>0.970819</td>\n",
       "      <td>0.985410</td>\n",
       "      <td>0.970819</td>\n",
       "      <td>0.976404</td>\n",
       "      <td>0.976404</td>\n",
       "      <td>0.975971</td>\n",
       "      <td>0.005339</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>9.890446</td>\n",
       "      <td>0.238805</td>\n",
       "      <td>0.283517</td>\n",
       "      <td>0.078698</td>\n",
       "      <td>60</td>\n",
       "      <td>300</td>\n",
       "      <td>{'max_depth': 60, 'n_estimators': 300}</td>\n",
       "      <td>0.973064</td>\n",
       "      <td>0.983165</td>\n",
       "      <td>0.970819</td>\n",
       "      <td>0.979775</td>\n",
       "      <td>0.971910</td>\n",
       "      <td>0.975747</td>\n",
       "      <td>0.004847</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>6.377703</td>\n",
       "      <td>0.105670</td>\n",
       "      <td>0.112100</td>\n",
       "      <td>0.016485</td>\n",
       "      <td>None</td>\n",
       "      <td>150</td>\n",
       "      <td>{'max_depth': None, 'n_estimators': 150}</td>\n",
       "      <td>0.970819</td>\n",
       "      <td>0.982043</td>\n",
       "      <td>0.971942</td>\n",
       "      <td>0.980899</td>\n",
       "      <td>0.970787</td>\n",
       "      <td>0.975298</td>\n",
       "      <td>0.005070</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>12.944284</td>\n",
       "      <td>0.366972</td>\n",
       "      <td>0.160782</td>\n",
       "      <td>0.014997</td>\n",
       "      <td>90</td>\n",
       "      <td>300</td>\n",
       "      <td>{'max_depth': 90, 'n_estimators': 300}</td>\n",
       "      <td>0.969697</td>\n",
       "      <td>0.983165</td>\n",
       "      <td>0.971942</td>\n",
       "      <td>0.979775</td>\n",
       "      <td>0.970787</td>\n",
       "      <td>0.975073</td>\n",
       "      <td>0.005379</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "7        5.532954      0.124660         0.291926        0.357877   \n",
       "11      10.040416      0.162150         0.159551        0.036358   \n",
       "5        9.890446      0.238805         0.283517        0.078698   \n",
       "10       6.377703      0.105670         0.112100        0.016485   \n",
       "8       12.944284      0.366972         0.160782        0.014997   \n",
       "\n",
       "   param_max_depth param_n_estimators  \\\n",
       "7               90                150   \n",
       "11            None                300   \n",
       "5               60                300   \n",
       "10            None                150   \n",
       "8               90                300   \n",
       "\n",
       "                                      params  split0_test_score  \\\n",
       "7     {'max_depth': 90, 'n_estimators': 150}           0.971942   \n",
       "11  {'max_depth': None, 'n_estimators': 300}           0.970819   \n",
       "5     {'max_depth': 60, 'n_estimators': 300}           0.973064   \n",
       "10  {'max_depth': None, 'n_estimators': 150}           0.970819   \n",
       "8     {'max_depth': 90, 'n_estimators': 300}           0.969697   \n",
       "\n",
       "    split1_test_score  split2_test_score  split3_test_score  \\\n",
       "7            0.985410           0.973064           0.979775   \n",
       "11           0.985410           0.970819           0.976404   \n",
       "5            0.983165           0.970819           0.979775   \n",
       "10           0.982043           0.971942           0.980899   \n",
       "8            0.983165           0.971942           0.979775   \n",
       "\n",
       "    split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "7            0.974157         0.976870        0.005050                1  \n",
       "11           0.976404         0.975971        0.005339                2  \n",
       "5            0.971910         0.975747        0.004847                3  \n",
       "10           0.970787         0.975298        0.005070                4  \n",
       "8            0.970787         0.975073        0.005379                5  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestClassifier()\n",
    "param = {'n_estimators': [10,150,300],\n",
    "        'max_depth': [30,60,90,None]}\n",
    "gs = GridSearchCV(rf,param,cv=5,n_jobs=-1)\n",
    "gs_fit = gs.fit(x_train_tfidf_vect, y_train)\n",
    "pd.DataFrame(gs_fit.cv_results_).sort_values('mean_test_score',ascending=False)[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>9.695344</td>\n",
       "      <td>0.162681</td>\n",
       "      <td>0.172313</td>\n",
       "      <td>0.027221</td>\n",
       "      <td>None</td>\n",
       "      <td>300</td>\n",
       "      <td>{'max_depth': None, 'n_estimators': 300}</td>\n",
       "      <td>0.971942</td>\n",
       "      <td>0.984287</td>\n",
       "      <td>0.970819</td>\n",
       "      <td>0.979775</td>\n",
       "      <td>0.974157</td>\n",
       "      <td>0.976196</td>\n",
       "      <td>0.005088</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>12.500582</td>\n",
       "      <td>0.082253</td>\n",
       "      <td>0.244724</td>\n",
       "      <td>0.027192</td>\n",
       "      <td>90</td>\n",
       "      <td>300</td>\n",
       "      <td>{'max_depth': 90, 'n_estimators': 300}</td>\n",
       "      <td>0.969697</td>\n",
       "      <td>0.983165</td>\n",
       "      <td>0.971942</td>\n",
       "      <td>0.979775</td>\n",
       "      <td>0.971910</td>\n",
       "      <td>0.975298</td>\n",
       "      <td>0.005216</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>6.150525</td>\n",
       "      <td>0.159996</td>\n",
       "      <td>0.138761</td>\n",
       "      <td>0.032560</td>\n",
       "      <td>None</td>\n",
       "      <td>150</td>\n",
       "      <td>{'max_depth': None, 'n_estimators': 150}</td>\n",
       "      <td>0.969697</td>\n",
       "      <td>0.984287</td>\n",
       "      <td>0.970819</td>\n",
       "      <td>0.979775</td>\n",
       "      <td>0.971910</td>\n",
       "      <td>0.975298</td>\n",
       "      <td>0.005723</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>11.057484</td>\n",
       "      <td>0.126267</td>\n",
       "      <td>0.466880</td>\n",
       "      <td>0.018200</td>\n",
       "      <td>60</td>\n",
       "      <td>300</td>\n",
       "      <td>{'max_depth': 60, 'n_estimators': 300}</td>\n",
       "      <td>0.970819</td>\n",
       "      <td>0.982043</td>\n",
       "      <td>0.969697</td>\n",
       "      <td>0.979775</td>\n",
       "      <td>0.973034</td>\n",
       "      <td>0.975074</td>\n",
       "      <td>0.004936</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5.749557</td>\n",
       "      <td>0.049706</td>\n",
       "      <td>0.165575</td>\n",
       "      <td>0.085135</td>\n",
       "      <td>90</td>\n",
       "      <td>150</td>\n",
       "      <td>{'max_depth': 90, 'n_estimators': 150}</td>\n",
       "      <td>0.969697</td>\n",
       "      <td>0.982043</td>\n",
       "      <td>0.970819</td>\n",
       "      <td>0.977528</td>\n",
       "      <td>0.974157</td>\n",
       "      <td>0.974849</td>\n",
       "      <td>0.004521</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "11       9.695344      0.162681         0.172313        0.027221   \n",
       "8       12.500582      0.082253         0.244724        0.027192   \n",
       "10       6.150525      0.159996         0.138761        0.032560   \n",
       "5       11.057484      0.126267         0.466880        0.018200   \n",
       "7        5.749557      0.049706         0.165575        0.085135   \n",
       "\n",
       "   param_max_depth param_n_estimators  \\\n",
       "11            None                300   \n",
       "8               90                300   \n",
       "10            None                150   \n",
       "5               60                300   \n",
       "7               90                150   \n",
       "\n",
       "                                      params  split0_test_score  \\\n",
       "11  {'max_depth': None, 'n_estimators': 300}           0.971942   \n",
       "8     {'max_depth': 90, 'n_estimators': 300}           0.969697   \n",
       "10  {'max_depth': None, 'n_estimators': 150}           0.969697   \n",
       "5     {'max_depth': 60, 'n_estimators': 300}           0.970819   \n",
       "7     {'max_depth': 90, 'n_estimators': 150}           0.969697   \n",
       "\n",
       "    split1_test_score  split2_test_score  split3_test_score  \\\n",
       "11           0.984287           0.970819           0.979775   \n",
       "8            0.983165           0.971942           0.979775   \n",
       "10           0.984287           0.970819           0.979775   \n",
       "5            0.982043           0.969697           0.979775   \n",
       "7            0.982043           0.970819           0.977528   \n",
       "\n",
       "    split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "11           0.974157         0.976196        0.005088                1  \n",
       "8            0.971910         0.975298        0.005216                2  \n",
       "10           0.971910         0.975298        0.005723                3  \n",
       "5            0.973034         0.975074        0.004936                4  \n",
       "7            0.974157         0.974849        0.004521                5  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestClassifier()\n",
    "param = {'n_estimators': [10,150,300],\n",
    "        'max_depth': [30,60,90,None]}\n",
    "gs = GridSearchCV(rf,param,cv=5,n_jobs=-1)\n",
    "gs_fit = gs.fit(x_train_count_vect, y_train)\n",
    "pd.DataFrame(gs_fit.cv_results_).sort_values('mean_test_score',ascending=False)[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84.589173</td>\n",
       "      <td>0.900306</td>\n",
       "      <td>0.144440</td>\n",
       "      <td>0.024969</td>\n",
       "      <td>0.1</td>\n",
       "      <td>11</td>\n",
       "      <td>150</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 11, 'n_est...</td>\n",
       "      <td>0.976431</td>\n",
       "      <td>0.984287</td>\n",
       "      <td>0.966330</td>\n",
       "      <td>0.982022</td>\n",
       "      <td>0.975281</td>\n",
       "      <td>0.976870</td>\n",
       "      <td>0.006251</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>58.334555</td>\n",
       "      <td>1.072242</td>\n",
       "      <td>0.139996</td>\n",
       "      <td>0.025437</td>\n",
       "      <td>0.1</td>\n",
       "      <td>11</td>\n",
       "      <td>100</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 11, 'n_est...</td>\n",
       "      <td>0.977553</td>\n",
       "      <td>0.982043</td>\n",
       "      <td>0.969697</td>\n",
       "      <td>0.982022</td>\n",
       "      <td>0.970787</td>\n",
       "      <td>0.976420</td>\n",
       "      <td>0.005315</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>79.270134</td>\n",
       "      <td>1.181677</td>\n",
       "      <td>0.111610</td>\n",
       "      <td>0.021344</td>\n",
       "      <td>0.1</td>\n",
       "      <td>15</td>\n",
       "      <td>150</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 15, 'n_est...</td>\n",
       "      <td>0.975309</td>\n",
       "      <td>0.980920</td>\n",
       "      <td>0.968575</td>\n",
       "      <td>0.984270</td>\n",
       "      <td>0.971910</td>\n",
       "      <td>0.976197</td>\n",
       "      <td>0.005740</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>37.876659</td>\n",
       "      <td>0.261181</td>\n",
       "      <td>0.298045</td>\n",
       "      <td>0.064644</td>\n",
       "      <td>0.1</td>\n",
       "      <td>7</td>\n",
       "      <td>100</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 7, 'n_esti...</td>\n",
       "      <td>0.975309</td>\n",
       "      <td>0.982043</td>\n",
       "      <td>0.967452</td>\n",
       "      <td>0.980899</td>\n",
       "      <td>0.973034</td>\n",
       "      <td>0.975747</td>\n",
       "      <td>0.005339</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>58.249934</td>\n",
       "      <td>0.680959</td>\n",
       "      <td>0.183177</td>\n",
       "      <td>0.048660</td>\n",
       "      <td>0.1</td>\n",
       "      <td>7</td>\n",
       "      <td>150</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 7, 'n_esti...</td>\n",
       "      <td>0.974186</td>\n",
       "      <td>0.982043</td>\n",
       "      <td>0.969697</td>\n",
       "      <td>0.979775</td>\n",
       "      <td>0.973034</td>\n",
       "      <td>0.975747</td>\n",
       "      <td>0.004522</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "3      84.589173      0.900306         0.144440        0.024969   \n",
       "2      58.334555      1.072242         0.139996        0.025437   \n",
       "5      79.270134      1.181677         0.111610        0.021344   \n",
       "0      37.876659      0.261181         0.298045        0.064644   \n",
       "1      58.249934      0.680959         0.183177        0.048660   \n",
       "\n",
       "  param_learning_rate param_max_depth param_n_estimators  \\\n",
       "3                 0.1              11                150   \n",
       "2                 0.1              11                100   \n",
       "5                 0.1              15                150   \n",
       "0                 0.1               7                100   \n",
       "1                 0.1               7                150   \n",
       "\n",
       "                                              params  split0_test_score  \\\n",
       "3  {'learning_rate': 0.1, 'max_depth': 11, 'n_est...           0.976431   \n",
       "2  {'learning_rate': 0.1, 'max_depth': 11, 'n_est...           0.977553   \n",
       "5  {'learning_rate': 0.1, 'max_depth': 15, 'n_est...           0.975309   \n",
       "0  {'learning_rate': 0.1, 'max_depth': 7, 'n_esti...           0.975309   \n",
       "1  {'learning_rate': 0.1, 'max_depth': 7, 'n_esti...           0.974186   \n",
       "\n",
       "   split1_test_score  split2_test_score  split3_test_score  split4_test_score  \\\n",
       "3           0.984287           0.966330           0.982022           0.975281   \n",
       "2           0.982043           0.969697           0.982022           0.970787   \n",
       "5           0.980920           0.968575           0.984270           0.971910   \n",
       "0           0.982043           0.967452           0.980899           0.973034   \n",
       "1           0.982043           0.969697           0.979775           0.973034   \n",
       "\n",
       "   mean_test_score  std_test_score  rank_test_score  \n",
       "3         0.976870        0.006251                1  \n",
       "2         0.976420        0.005315                2  \n",
       "5         0.976197        0.005740                3  \n",
       "0         0.975747        0.005339                4  \n",
       "1         0.975747        0.004522                5  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gb = GradientBoostingClassifier()\n",
    "param = {'n_estimators': [100,150],\n",
    "        'max_depth': [7,11,15],\n",
    "        'learning_rate': [0.1]}\n",
    "gs_tfidf_gb = GridSearchCV(gb,param,cv=5,n_jobs=-1)\n",
    "gs_tfidf_gb_fit = gs_tfidf_gb.fit(x_train_tfidf_vect, y_train)\n",
    "pd.DataFrame(gs_tfidf_gb_fit.cv_results_).sort_values('mean_test_score',ascending=False)[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>74.456795</td>\n",
       "      <td>0.684483</td>\n",
       "      <td>0.120620</td>\n",
       "      <td>0.018651</td>\n",
       "      <td>0.1</td>\n",
       "      <td>11</td>\n",
       "      <td>150</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 11, 'n_est...</td>\n",
       "      <td>0.978676</td>\n",
       "      <td>0.983165</td>\n",
       "      <td>0.968575</td>\n",
       "      <td>0.983146</td>\n",
       "      <td>0.971910</td>\n",
       "      <td>0.977094</td>\n",
       "      <td>0.005923</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>73.105423</td>\n",
       "      <td>0.785539</td>\n",
       "      <td>0.107260</td>\n",
       "      <td>0.009142</td>\n",
       "      <td>0.1</td>\n",
       "      <td>15</td>\n",
       "      <td>150</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 15, 'n_est...</td>\n",
       "      <td>0.978676</td>\n",
       "      <td>0.980920</td>\n",
       "      <td>0.965208</td>\n",
       "      <td>0.984270</td>\n",
       "      <td>0.968539</td>\n",
       "      <td>0.975523</td>\n",
       "      <td>0.007359</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>34.978914</td>\n",
       "      <td>0.223799</td>\n",
       "      <td>0.242415</td>\n",
       "      <td>0.065605</td>\n",
       "      <td>0.1</td>\n",
       "      <td>7</td>\n",
       "      <td>100</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 7, 'n_esti...</td>\n",
       "      <td>0.975309</td>\n",
       "      <td>0.982043</td>\n",
       "      <td>0.965208</td>\n",
       "      <td>0.980899</td>\n",
       "      <td>0.973034</td>\n",
       "      <td>0.975298</td>\n",
       "      <td>0.006063</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>52.524562</td>\n",
       "      <td>0.352642</td>\n",
       "      <td>0.163598</td>\n",
       "      <td>0.054052</td>\n",
       "      <td>0.1</td>\n",
       "      <td>7</td>\n",
       "      <td>150</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 7, 'n_esti...</td>\n",
       "      <td>0.973064</td>\n",
       "      <td>0.982043</td>\n",
       "      <td>0.967452</td>\n",
       "      <td>0.979775</td>\n",
       "      <td>0.973034</td>\n",
       "      <td>0.975074</td>\n",
       "      <td>0.005234</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>55.302371</td>\n",
       "      <td>1.188716</td>\n",
       "      <td>0.120369</td>\n",
       "      <td>0.012217</td>\n",
       "      <td>0.1</td>\n",
       "      <td>15</td>\n",
       "      <td>100</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 15, 'n_est...</td>\n",
       "      <td>0.976431</td>\n",
       "      <td>0.978676</td>\n",
       "      <td>0.965208</td>\n",
       "      <td>0.983146</td>\n",
       "      <td>0.969663</td>\n",
       "      <td>0.974625</td>\n",
       "      <td>0.006412</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "3      74.456795      0.684483         0.120620        0.018651   \n",
       "5      73.105423      0.785539         0.107260        0.009142   \n",
       "0      34.978914      0.223799         0.242415        0.065605   \n",
       "1      52.524562      0.352642         0.163598        0.054052   \n",
       "4      55.302371      1.188716         0.120369        0.012217   \n",
       "\n",
       "  param_learning_rate param_max_depth param_n_estimators  \\\n",
       "3                 0.1              11                150   \n",
       "5                 0.1              15                150   \n",
       "0                 0.1               7                100   \n",
       "1                 0.1               7                150   \n",
       "4                 0.1              15                100   \n",
       "\n",
       "                                              params  split0_test_score  \\\n",
       "3  {'learning_rate': 0.1, 'max_depth': 11, 'n_est...           0.978676   \n",
       "5  {'learning_rate': 0.1, 'max_depth': 15, 'n_est...           0.978676   \n",
       "0  {'learning_rate': 0.1, 'max_depth': 7, 'n_esti...           0.975309   \n",
       "1  {'learning_rate': 0.1, 'max_depth': 7, 'n_esti...           0.973064   \n",
       "4  {'learning_rate': 0.1, 'max_depth': 15, 'n_est...           0.976431   \n",
       "\n",
       "   split1_test_score  split2_test_score  split3_test_score  split4_test_score  \\\n",
       "3           0.983165           0.968575           0.983146           0.971910   \n",
       "5           0.980920           0.965208           0.984270           0.968539   \n",
       "0           0.982043           0.965208           0.980899           0.973034   \n",
       "1           0.982043           0.967452           0.979775           0.973034   \n",
       "4           0.978676           0.965208           0.983146           0.969663   \n",
       "\n",
       "   mean_test_score  std_test_score  rank_test_score  \n",
       "3         0.977094        0.005923                1  \n",
       "5         0.975523        0.007359                2  \n",
       "0         0.975298        0.006063                3  \n",
       "1         0.975074        0.005234                4  \n",
       "4         0.974625        0.006412                5  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gb = GradientBoostingClassifier()\n",
    "param = {'n_estimators': [100,150],\n",
    "        'max_depth': [7,11,15],\n",
    "        'learning_rate': [0.1]}\n",
    "gs_count_gb = GridSearchCV(gb,param,cv=5,n_jobs=-1)\n",
    "gs_count_gb_fit = gs_count_gb.fit(x_train_count_vect, y_train)\n",
    "pd.DataFrame(gs_count_gb_fit.cv_results_).sort_values('mean_test_score',ascending=False)[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Base on the data it does seem that the differences are very small with notable things like the mean_fit_time being very long but other than that they probably have the same mean test score. Hence we will pick the one that is the fastest out of all of them which is the randomforestclassifier. But we will compare them against each other in their score function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit time: 1.094 / Predict time: 0.082 ---- Precision: 1.0 / Recall: 0.813 / Accuracy: 0.975\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(n_estimators=150,max_depth=90,n_jobs=-1)\n",
    "\n",
    "start_fit = time.time()\n",
    "rf_model = rf.fit(x_train_tfidf_vect, y_train)\n",
    "end_fit = time.time()\n",
    "fit_time = end_fit - start_fit\n",
    "\n",
    "start_pred = time.time()\n",
    "rf_pred = rf_model.predict(x_test_tfidf_vect)\n",
    "end_pred = time.time()\n",
    "pred_time = end_pred - start_pred\n",
    "\n",
    "precision, recall, fscore, train_support = score(y_test, rf_pred, pos_label=1, average='binary')\n",
    "print('Fit time: {} / Predict time: {} ---- Precision: {} / Recall: {} / Accuracy: {}'.format(\n",
    "    round(fit_time,3),round(pred_time,3),round(precision,3),round(recall,3),round((rf_pred==y_test).sum()/len(rf_pred),3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit time: 1.808 / Predict time: 0.103 ---- Precision: 1.0 / Recall: 0.807 / Accuracy: 0.974\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(n_estimators=300,max_depth=None,n_jobs=-1)\n",
    "\n",
    "start_fit = time.time()\n",
    "rf_model = rf.fit(x_train_count_vect, y_train)\n",
    "end_fit = time.time()\n",
    "fit_time = end_fit - start_fit\n",
    "\n",
    "start_pred = time.time()\n",
    "rf_pred = rf_model.predict(x_test_count_vect)\n",
    "end_pred = time.time()\n",
    "pred_time = end_pred - start_pred\n",
    "\n",
    "precision, recall, fscore, train_support = score(y_test, rf_pred, pos_label=1, average='binary')\n",
    "print('Fit time: {} / Predict time: {} ---- Precision: {} / Recall: {} / Accuracy: {}'.format(\n",
    "    round(fit_time,3),round(pred_time,3),round(precision,3),round(recall,3),round((rf_pred==y_test).sum()/len(rf_pred),3)))\n",
    "\n",
    "# Precision is the ratio of correctly predicted positive observations to the total predicted positives. \n",
    "# Eg. of all the emails that were predicted as spam, how many were actually spam.\n",
    "\n",
    "# Recall is the ratio of correctly predicted positive observations to the all observations in actual class.\n",
    "# Eg. of all the emails that were actually spam, how many were predicted as spam.\n",
    "\n",
    "# F1 Score is the weighted average of Precision and Recall. Therefore, this score takes both false positives and false negatives into account."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit time: 82.43 / Predict time: 0.118 ---- Precision: 0.969 / Recall: 0.827 / Accuracy: 0.973\n"
     ]
    }
   ],
   "source": [
    "gb = GradientBoostingClassifier(n_estimators=150,max_depth=11,learning_rate=0.1)\n",
    "\n",
    "start_fit = time.time()\n",
    "gb_fit = gb.fit(x_train_tfidf_vect, y_train)\n",
    "end_fit = time.time()\n",
    "fit_time = end_fit - start_fit\n",
    "\n",
    "start_pred = time.time()\n",
    "gb_pred = gb_fit.predict(x_test_tfidf_vect)\n",
    "end_pred = time.time()\n",
    "pred_time = end_pred - start_pred\n",
    "\n",
    "precision, recall, fscore, train_support = score(y_test, gb_pred, pos_label=1, average='binary')\n",
    "print('Fit time: {} / Predict time: {} ---- Precision: {} / Recall: {} / Accuracy: {}'.format(\n",
    "    round(fit_time,3),round(pred_time,3),round(precision,3),round(recall,3),round((gb_pred==y_test).sum()/len(gb_pred),3)))\n",
    "\n",
    "# Precision is the ratio of correctly predicted positive observations to the total predicted positives. \n",
    "# Eg. of all the emails that were predicted as spam, how many were actually spam.\n",
    "\n",
    "# Recall is the ratio of correctly predicted positive observations to the all observations in actual class.\n",
    "# Eg. of all the emails that were actually spam, how many were predicted as spam.\n",
    "\n",
    "# F1 Score is the weighted average of Precision and Recall. Therefore, this score takes both false positives and false negatives into account."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
